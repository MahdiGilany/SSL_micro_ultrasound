# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /trainer: exact_trainer.yaml
  - override /datamodule: exact_datamodule.yaml
  - override /model: exact_ssl_module.yaml
  - override /callbacks: exact_callbacks_ssl.yaml
  - override /logger: wandb

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

# name of the run determines folder name in logs
name: "test_vicreg"

seed: 12345

trainer:
  min_epochs: 100
  max_epochs: 100
  gradient_clip_val: null
  limit_train_batches: null
  limit_val_batches: null

datamodule:
  batch_size: 32
  num_workers: 4
  train_val_split: 0.25 # ratio of train to val dataset length
  split_randomstate: 26 # random state for above random split
  dataset_hyp: # dataset hyperparameters
    SSL: True
    patch_sz: 5 # patch size in mm
    jump_sz: 1 # jump of each patch to create next patch
    inv_cutoff: 0.4 # cutoff involvement to exclude low inv data in train/test/val
    # list of applied augmentations ['RandomInvert', 'RandomVerticalFlip', 'RandomHorizontalFlip', 'RandomAffine', 'RandomErasing', 'RandomEqualize']
    aug_list: ['RandomVerticalFlip', 'RandomHorizontalFlip', 'RandomAffine', 'RandomErasing']
    aug_prob: 0.1 # probability of augmentations

model:
  _target_: src.models.exact_ssl_module.VICReg
  lr: 0.0001
  batch_size: ${datamodule.batch_size}
  # method specific parameters
  proj_output_dim: 512
  proj_hidden_dim: 512
  sim_loss_weight: 25.
  var_loss_weight: 25.
  cov_loss_weight: 1.

logger:
  wandb:
    name: ${name}_inv-cut${datamodule.dataset_hyp.inv_cutoff}_srs${datamodule.split_randomstate}_split${datamodule.train_val_split}
    tags: ["exact", "test", "${name}"]
