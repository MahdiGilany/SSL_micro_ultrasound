_target_: src.models.self_supervised.finetuner_module.ExactCoreFineTuner

head_network: "attention_classifier"

backbone:
  _target_: src.models.self_supervised.vicreg.vicreg_module.VICReg
  backbone: resnet10
  proj_output_dim: 512
  proj_hidden_dim: 512

in_features: 512
num_classes: 2

dropout: 0.0
optim_algo: "Adam"
weight_decay: 1e-6
scheduler_type: "warmup_cosine"
decay_epochs: (60,80)
gamma: 0.1
final_lr: 0.0

ckpt_path: null
semi_sup: False
batch_size: ${datamodule.batch_size}
epochs: ${trainer.max_epochs}
learning_rate: 0.0001 # learning rate of finetuning step


