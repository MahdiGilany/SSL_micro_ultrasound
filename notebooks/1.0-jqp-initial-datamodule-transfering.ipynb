{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seting up directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.datamodules.exact_datamodule import ExactDataModule\n",
    "from scipy.io import matlab\n",
    "from einops import rearrange\n",
    "from itertools import product\n",
    "import munch\n",
    "import numpy as np\n",
    "import torch\n",
    "from ismember import ismember\n",
    "from src.datamodules.components.data_utils import *\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.data as sd\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from matplotlib.colors import NoNorm\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from torchvision.transforms import transforms\n",
    "%matplotlib inline\n",
    "\n",
    "original_dir = os.getcwd()\n",
    "original_dir = original_dir.split(\"\\\\\")\n",
    "original_dir = '\\\\'.join(original_dir[:-1])\n",
    "\n",
    "data_dir = original_dir + '\\data\\Exact\\\\'\n",
    "data_file = 'Exact_UVA_patches_400_100_100_indivPatchesNames_03-16-2022.mat'\n",
    "print(data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load matlab and convert to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = matlab.loadmat(data_dir+data_file, struct_as_record=False, squeeze_me=True)\n",
    "with open(data_dir+'metadata.pkl', 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "for i in range(1):\n",
    "    with open(data_dir+'metadata.pkl', 'rb') as handle:\n",
    "        meta_data = pickle.load(handle)\n",
    "end = time.time()\n",
    "print(end-st)\n",
    "print(meta_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing patch extraction and patch center finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "centers = meta_data['patch_centers1x1']\n",
    "needle_mask = meta_data['needle_mask']\n",
    "\n",
    "# changing dimensionality of patch centers\n",
    "centers = rearrange(centers, '(ax c) lat -> ax c lat', ax=28)\n",
    "patch_mask = needle_mask[centers[:, 0, 0][:, None], centers[:, :, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "jump = 2\n",
    "patch_sz = 4\n",
    "\n",
    "# finding lateral index of central patch\n",
    "col_select = np.sum(patch_mask, axis=0)\n",
    "ind_lat = np.argwhere(col_select>0)\n",
    "st_lat = ind_lat[0].item() + np.floor((patch_sz-1)/2.).astype(int)\n",
    "end_lat = ind_lat[-1].item() - np.ceil((patch_sz-1)/2.).astype(int)\n",
    "\n",
    "patch_centersSL = []\n",
    "patch_indx = []\n",
    "for i in range(st_lat,end_lat+1,jump):\n",
    "    # finding axial index of central patch\n",
    "    ind_ax = np.argwhere(patch_mask[:,i]>0)\n",
    "    j = np.floor(ind_ax.mean()).astype(int)\n",
    "\n",
    "    # finding actual patch center from indices and saving it\n",
    "    patch_indx.append(np.array([[j,i]]))\n",
    "    cent = np.array([[centers[j, 0, 0],centers[0, i, 1]]])\n",
    "    patch_centersSL.append(cent)\n",
    "\n",
    "p = np.concatenate(patch_centersSL)\n",
    "p2 = np.concatenate(patch_indx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### coloring patch needle mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hlf_sz = np.floor((patch_sz-1)/2.).astype(int)\n",
    "hlf_rest = np.ceil((patch_sz-1)/2.).astype(int)\n",
    "new_patch_mask = np.zeros_like(patch_mask)\n",
    "for ind, c in enumerate(p2):\n",
    "    print(c, list(range(c[0]-hlf_sz,c[0]+hlf_rest+1)), list(range(c[1]-hlf_sz,c[1]+hlf_rest+1)))\n",
    "    new_patch_mask[c[0]-hlf_sz:c[0]+hlf_rest+1, c[1]-hlf_sz:c[1]+hlf_rest+1] += 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_hyp = {'patch_sz':5, 'jump_sz':1}\n",
    "dataset_hyp = munch.Munch(dataset_hyp)\n",
    "dataset_hyp.jump_sz\n",
    "datamodule = ExactDataModule(data_dir, dataset_hyp=dataset_hyp)\n",
    "datamodule.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finding size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "meta_data = datamodule.meta_data\n",
    "data_names = meta_data[f'data_train']\n",
    "all_patchnames_sl = []\n",
    "for i, patch_names_pr in enumerate(data_names):\n",
    "    all_patchnames_pr = [np.array(name.split('_')[-3:-1]).astype(int) for name in patch_names_pr]\n",
    "    all_patchnames_pr = np.stack(all_patchnames_pr)\n",
    "    ind,_ = ismember(all_patchnames_pr, datamodule.patch_centers_sl, \"rows\")\n",
    "    # ### validate function\n",
    "    # all_patchcenters_pr = all_patchnames_pr\n",
    "    # all_1x1patchnames_sl_pr = all_patchcenters_pr[ind]\n",
    "    # all_1x1patchnames_sl_pr[0]\n",
    "\n",
    "    all_patchnames_sl.append(patch_names_pr[ind])\n",
    "\n",
    "all_core_len = [core.shape[0] for core in all_patchnames_sl]\n",
    "np.sum(all_core_len)\n",
    "all_patchnames_sl_concat = np.concatenate(all_patchnames_sl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing patch with the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file_name='UVA-0012_LBL_GS9_1612_292_frm1.mat'\n",
    "patch_data = load_matlab73(data_dir+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_dir+'UVA-0012_LBL_GS9_1612_292_frm1.pkl', 'wb') as handle:\n",
    "    pickle.dump(patch_data['data'], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "st = time.time()\n",
    "for i in range(100):\n",
    "    # with open(data_dir+'UVA-0012_LBL_GS9_1612_292_frm1.pkl', 'rb') as handle:\n",
    "    #     patch_data2 = pickle.load(handle)\n",
    "    patch_data = load_matlab73(data_dir+file_name)\n",
    "\n",
    "end = time.time()\n",
    "print(end-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "folder_name = 'patch1x1_data'\n",
    "list_all_files = []\n",
    "list_all_roots = []\n",
    "for root, dir, files in os.walk(data_dir):\n",
    "    # file_dir = [root+'\\\\'+ f for i, f in enumerate(files)]\n",
    "    # list_all_files.append(file_dir)\n",
    "    list_all_roots.append(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ismember import ismember\n",
    "file_name='UVA-0012_LBL_GS9_1612_292_frm1.mat'\n",
    "file_root = '_'.join(file_name.split('_')[:-3])\n",
    "\n",
    "st = time.time()\n",
    "for j in range(25*32):\n",
    "    complete_fileroot = [f for f in list_all_roots if file_root in f]\n",
    "print(time.time()-st)\n",
    "complete_fileroot = os.path.join(complete_fileroot[0], file_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load meta data\n",
    "with open(data_dir+'metadata.pkl', 'rb') as handle:\n",
    "        meta_data = pickle.load(handle)\n",
    "patch_centers_RFimg = meta_data['patch_centers1x1']\n",
    "patch_centers_RFimg = [np.unique(patch_centers_RFimg[:, 0]), np.unique(patch_centers_RFimg[:, 1])]\n",
    "cent_axl_ind, = np.where(patch_centers_RFimg[0] == 1612)\n",
    "cent_lat_ind, = np.where(patch_centers_RFimg[1] == 291)\n",
    "\n",
    "hlf_patch_sz = np.floor((5-1)/2.).astype(int)\n",
    "hlf_patch_sz_rest = np.ceil((5-1)/2.).astype(int)\n",
    "cent_axl_range_ind = np.arange(cent_axl_ind[0]-hlf_patch_sz, cent_axl_ind[0]+hlf_patch_sz_rest+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### stitching patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_1x1patches = []\n",
    "st = time.time()\n",
    "for axl_ind, lat_ind in product(range(5),range(5)):\n",
    "    all_1x1patches.append(load_matlab73(data_dir+file_name)['data'])\n",
    "print(time.time()-st)\n",
    "all_1x1patches = np.stack(all_1x1patches)\n",
    "all_1x1patches = rearrange(all_1x1patches,'(b1 b2) h w -> (b1 h) (b2 w)', b1=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = sd.astronaut()\n",
    "img = rearrange(img,'(b1 h) (b2 w) c -> (b1 b2) h w c', b1=8, b2=8)\n",
    "img = rearrange(img,'(b1 b2) h w c -> (b1 h) (b2 w) c', b1=8)\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "img = np.array(Image.fromarray(img).resize((512,512)))[:,:,0]\n",
    "img = (img - np.mean(img, keepdims=True))/np.std(img, keepdims=True)\n",
    "me=np.std(img)\n",
    "print(me)\n",
    "# plt.imshow(img, 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saving all files in pkl format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for root, dir, files in os.walk(data_dir+'patches1x1'):\n",
    "    for file in files:\n",
    "        file_root = os.path.join(root,file)\n",
    "        patch_data = load_matlab73(file_root)\n",
    "        if 'data' in patch_data.keys():\n",
    "            pkl_name = '_'.join(file_root.split('_')[:-1]) + '_frm1.pkl'\n",
    "            with open(pkl_name, 'wb') as handle:\n",
    "                pickle.dump(patch_data['data'], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open(data_dir + 'UVA-0012_LBL_GS9_1612_292_frm1.pkl', 'wb') as handle:\n",
    "#     pickle.dump(patch_data['data'], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing datamodule and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_hyp = {'patch_sz':5, 'jump_sz':1, 'inv_cutoff':0.4}\n",
    "dataset_hyp = munch.Munch(dataset_hyp)\n",
    "\n",
    "datamodule = ExactDataModule(data_dir, dataset_hyp=dataset_hyp)\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len_train = len(datamodule.train_ds)\n",
    "len_test = len(datamodule.test_ds)\n",
    "len_val = len(datamodule.val_ds)\n",
    "n_cancer = np.sum(datamodule.val_ds.labels)\n",
    "\n",
    "corelen = datamodule.train_ds.all_corelen_sl\n",
    "st = time.time()\n",
    "for k in range(1):\n",
    "    try:\n",
    "        img, target = datamodule.train_ds.__getitem__(k)\n",
    "    except:\n",
    "        print(k)\n",
    "print(time.time()-st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img, target = datamodule.train_ds.__getitem__(1)\n",
    "print(img.mean(), img.std())\n",
    "fig = plt.figure(figsize=(18.5/2, 10.5/2))\n",
    "ax = fig.add_subplot()\n",
    "# plt.imshow(img, 'gray', norm=NoNorm())\n",
    "plt.imshow(img[0,...], 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = datamodule.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    st = time.time()\n",
    "    batch = next(iter(train_loader))\n",
    "    x, y = batch\n",
    "    print(time.time()-st)\n",
    "\n",
    "    index = 0\n",
    "    print(y[index])\n",
    "    fig = plt.figure(figsize=(18.5, 10.5))\n",
    "    ax = fig.add_subplot()\n",
    "    img_ = Image.fromarray(x[index,0,:,:].numpy()).resize((359*2, 1795))\n",
    "    img_= (img_ - np.mean(img_, keepdims=True))/np.std(img_, keepdims=True)\n",
    "    plt.imshow(img_[:359*2,:], 'gray',norm=NoNorm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing datamodule with hydra (hydra removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_hyp = {'patch_sz':5, 'jump_sz':1, 'inv_cutoff':0.4, 'aug_list': [], 'aug_prob': 1., 'SSL': False}\n",
    "dataset_hyp = munch.Munch(dataset_hyp)\n",
    "datamodule = ExactDataModule(data_dir, dataset_hyp=dataset_hyp)\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()\n",
    "\n",
    "train_loader = datamodule.train_dataloader()\n",
    "batch = next(iter(train_loader))\n",
    "x, y = batch\n",
    "x_tensor = x[0,0,...]\n",
    "plt.figure(figsize=(18.5/2, 10.5/2))\n",
    "plt.imshow(x_tensor, 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### applying transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m = 5\n",
    "n = 6\n",
    "img = np.copy(x[m:n,0,...].numpy())\n",
    "img = img.reshape(n-m,-1)\n",
    "img = rearrange(img, 'b pix-> pix b')\n",
    "plt.hist(img, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = x[2,...].numpy()\n",
    "# img = (img - np.mean(img, ))/np.std(img, )\n",
    "\n",
    "transforms_ = aug_transforms('train', ['RandomHorizontalFlip'], p=0.)\n",
    "img2 = apply_transforms(img, transforms_)\n",
    "\n",
    "# img = rearrange(img, 'c h w -> h w c')\n",
    "# img[img > 4] = 4.\n",
    "# img[img < -4] = -4.\n",
    "# img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "# transforms_ = transforms.Compose(\n",
    "#     [transforms.ToTensor(), transforms.RandomErasing(1., scale=(0.01, 0.05),ratio=(0.3, 3.3), value=0)]\n",
    "# )\n",
    "\n",
    "# img2 = transforms_(np.copy(img))\n",
    "# img2 = (img2 - torch.mean(img2, ))/torch.std(img2, )\n",
    "# img2 = (img2 - .24708273)/848.8191\n",
    "print(img2.mean(), img2.std())\n",
    "plt.figure(figsize=(18.5/1.5, 10.5/1.5))\n",
    "plt.imshow(img2[0], 'gray', norm=NoNorm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img2 = img2[0,...].numpy()\n",
    "img = img[:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding mean and standard deviation of training + val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_hyp = {'patch_sz':5, 'jump_sz':1, 'inv_cutoff':0.4}\n",
    "dataset_hyp = munch.Munch(dataset_hyp)\n",
    "datamodule = ExactDataModule(data_dir,batch_size=4000, dataset_hyp=dataset_hyp)\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = datamodule.train_dataloader()\n",
    "val_loader, = datamodule.val_dataloader()\n",
    "batch_train = next(iter(train_loader))\n",
    "batch_val = next(iter(val_loader))\n",
    "x_train, y = batch_train\n",
    "x_val, y = batch_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.cat([x_train, x_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(x.size())\n",
    "all_x = x.numpy()\n",
    "print(all_x.mean(), all_x.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.datamodules.mnist_datamodule import MNISTDataModule\n",
    "from torchvision.datasets import MNIST\n",
    "mnist_dir = 'C:\\\\Users\\\\Mahdi\\\\Desktop\\\\Shared_folder\\\\OneDrive_Queens_University\\\\Project_codes\\\\SSLmicroUltrasound\\\\data\\\\'\n",
    "mnist_ds = MNIST(mnist_dir, train=True, download=False)\n",
    "mnist_img, _ = mnist_ds.__getitem__(105)\n",
    "plt.imshow(mnist_img, 'gray')\n",
    "tensor_mnist = np.array(mnist_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transforms_ = transforms.Compose([transforms.ToTensor(), transforms.RandomInvert(p=1.),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "tensor_mnist2 = transforms_(tensor_mnist).numpy()\n",
    "print(tensor_mnist2.mean(), tensor_mnist2.std())\n",
    "plt.imshow(tensor_mnist2[0,:,:], 'gray', norm=NoNorm())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
